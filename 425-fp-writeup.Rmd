---
title: "Stormy Weather Stormy Sales"
author: 
- "Jonathan Lu"
- "Kara Wong"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document: 
    theme: cosmo
    toc: yes
urlcolor: BrickRed
---

***

```{r setup, include = FALSE}
knitr::opts_chunk$set(fig.align = 'center', message = FALSE, warning = FALSE)
```

```{r load-packages, include = FALSE}
library(lubridate)
library(hydroTSM)
library(imputeTS)
library(rlist)
library(tidyverse)
library(caret)
library(knitr)
library(kableExtra)
```

```{r reading-data, include = FALSE}
trn_data = read_csv("data/train.csv")
tst_data = read_csv("data/test.csv")
key = read_csv("data/key.csv")
weather_data = read_csv("data/weather.csv")
```

## Looking at weather data missing values

```{r explore-missing-obs}
w_g = weather_data %>%
    group_by(station_nbr) %>%
    group_split()

miss_vars = lapply(w_g, function(dat){
    miss_vals = c()
    for(i in 3:ncol(dat)){
        miss_vals[i-2] = ifelse(sum(is.na(dat[,i])) > 0, paste(sum(is.na(dat[,i])), "NA values"), 
                                ifelse(sum(dat[,i] == "M") > 0, paste(sum(dat[,i] == "M"), "M"), 
                                    ifelse(sum(dat[,i] == "-") > 0, paste(sum(dat[,i] == "-"),"VNA"),
                                           ifelse(sum(dat[,i] == "T"), paste(sum(dat[,i] == "T"), "Trace"), "OK"))))
    }
    names(miss_vals) <- names(dat)[3:ncol(dat)]
    return(miss_vals)
})

weather_status = as.data.frame(do.call(rbind, miss_vars))
```

## Date Range Exploration

```{r d-range-1}
trn_dates_store = trn_data %>%
    group_by(store_nbr) %>%
    summarise(min(date), max(date))

trn_range = c(max(trn_dates_store$`min(date)`), min(trn_dates_store$`max(date)`))
```

All obsevations stores recorded observations from `r trn_dates_store[1,2]` to `r trn_dates_store[1,3]` expect for store 35 which ranges from `r trn_range` and 

```{r d-range-2}
wthr_dates_store = weather_data %>%
    group_by(station_nbr) %>%
    summarise(min(date), max(date))

wthr_range = c(max(wthr_dates_store$`min(date)`), min(wthr_dates_store$`max(date)`))
```

Thankfully weather data matches the dates when they're equally as fucked up, every weather station besides number 5 range from `r trn_dates_store[1,2]` to `r trn_dates_store[1,3]` and station 5 (matching) ranges from `r wthr_range`.

## Convert data to different variables

*Removed weather data vars*

- `tavg` - Almost perfectly collinear with tmin and tmax
- `depart` - Too many missing values across all stations `r sum(weather_data$depart == "M")/nrow(weather_data)*100`% of all data
- `sunrise` - Too many missing values across all stations and probably irrelevant `r sum(weather_data$sunrise == "-")/nrow(weather_data) * 100`% of all data
- `sunset` - Too many missing values across all stations and probably irrelevant `r sum(weather_data$sunset == "-")/nrow(weather_data) * 100`% of all data
- `snowfall` - Too many missing values across all stations `r sum(weather_data$snowfall == "M")/nrow(weather_data) * 100`% of all data
- `sealevel` - Pretty much identical to stnpressure as they are both measurements of pressure and stnpressure isn't missing data.

## Creating and Imputing Values

```{r creating-vars}
# change code sum so that its a categorical variable ie something happaned or not

weather_data_c = weather_data %>% 
    select(-depart, -sunrise, -sunset, -snowfall, -tavg, -sealevel) %>%
    mutate(
        codesum = ifelse(is.na(weather_data$codesum), 0, 1),
        isWeekend =  ifelse(wday(weather_data$date) %in% c(6,7), 1, 0),
        season = factor(time2season(weather_data$date, out.fmt = "seasons"))
)

# Replace trace with an arbitrarily small value

weather_data_c$preciptotal[weather_data_c$preciptotal == "T"] = .005

#View(head(weather_data_c, 100))
```

- `season` (Categorical)
- `isWeekend` (Categorical)
- `tmax` (Continuous)
- `tmin` (Continuous)
- `codesum` (Categorical)

```{r imputing-4day-smoothing}
w_g = weather_data_c %>% 
    group_by(station_nbr) %>%
    group_split()

# 4 day exponential smoothing average

dlist = lapply(w_g[c(1,2,3,4,6:20)], function(dat){
    m = dat[,-c(1,2,9,15,16)]
    m[m == "M"] = NA
    for(i in 1:ncol(m)){
        m[,i] = na_ma(as.numeric(m[[i]]), weighting = "simple")
    }
    dat[,-c(1,2,9,15,16)] = m
    return(dat)
})

dlist = list.insert(dlist, 5, w_g[[5]])

weather_data_c = as.data.frame(do.call(rbind, dlist)) 
```

```{r imputing-median-stat5}
sd = w_g[[5]]$date

wd_c_date = weather_data_c[weather_data_c$date %in% sd, 1:14]

wd_c_date = wd_c_date[wd_c_date$station_nbr != 5, ]

f = wd_c_date %>%
    group_by(date) %>%
    summarise_all(funs(mean))

weather_data_c[is.na(weather_data_c$tmax), 3] = f[is.na(w_g[[5]]$tmax), 3]
weather_data_c[is.na(weather_data_c$tmin), 4] = f[is.na(w_g[[5]]$tmin), 4]

for(i in 5:(ncol(weather_data_c) - 2)){
    weather_data_c[weather_data_c[,i] == "M", i] = f[w_g[[5]][,i] == "M", i]
}

```

```{r, include = FALSE, eval = FALSE}
w_g = weather_data_c %>% 
    group_by(station_nbr) %>%
    group_split()

miss_vars = lapply(w_g, function(dat){
    miss_vals = c()
    for(i in 3:ncol(dat)){
        miss_vals[i-2] = ifelse(sum(is.na(dat[,i])) > 0, paste(sum(is.na(dat[,i])), "NA values"), 
                                ifelse(sum(dat[,i] == "M") > 0, paste(sum(dat[,i] == "M"), "M"), 
                                    ifelse(sum(dat[,i] == "-") > 0, paste(sum(dat[,i] == "-"),"VNA"),
                                           ifelse(sum(dat[,i] == "T"), paste(sum(dat[,i] == "T"), "Trace"), "OK"))))
    }
    names(miss_vals) <- names(dat)[3:ncol(dat)]
    return(miss_vals)
})

weather_status = as.data.frame(do.call(rbind, miss_vars))

#View(weather_status)
```



## Stitching together data

```{r s5}
trn_data = trn_data %>%
    left_join(., key, by = c("store_nbr")) %>%
    left_join(., weather_data_c, by = c("station_nbr", "date"))

```



```{r, eval = FALSE}
set.seed(425)
sample_ind = createDataPartition(trn_data$store_nbr, list = FALSE, p = .05)

f_sam = trn_data[sample_ind,]

#f_sam = type.convert(f_sam)

#f_sam$codesum = as.factor(f_sam$codesum)
#f_sam$isWeekend = as.factor(f_sam$isWeekend)

write_csv(f_sam, "data/sample_trn.csv")
```


```{r readinsample}
trn_sample = read_csv("data/sample_trn.csv")
trn_sample$store_nbr = as.factor(trn_sample$store_nbr)
trn_sample$item_nbr = as.factor(trn_sample$item_nbr)
trn_sample$isWeekend = as.factor(ifelse(trn_sample$isWeekend, "weekend", "weekday"))
levels(trn_sample$isWeekend) = c("weekday", "weekend")
trn_sample$store_nbr = as.factor(trn_sample$store_nbr)
trn_sample$codesum = as.factor(ifelse(trn_sample$codesum, "event", "no-event"))
levels(trn_sample$codesum) = c("no-event", "event")
```


## Linear Model

Before we could build our first linear model, we had to stitch the weather data to the original dataset provided by Walmart. The main bulk of the work when it came to this process was cleaning the weather data to a point where it could be added together.

At an initial glance, we could see that the weather data was extremely incomplete.

```{r init-weather}
weather_status %>%
    kable(caption = "M, NA, and VNA represent the count of M's, -'s, and NA's respectively") %>%
    kable_styling("striped", full_width = FALSE)
    
```





